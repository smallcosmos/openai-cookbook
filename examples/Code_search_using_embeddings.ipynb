{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code search using embeddings\n",
    "\n",
    "This notebook shows how Ada embeddings can be used to implement semantic code search. For this demonstration, we use our own [openai-python code repository](https://github.com/openai/openai-python). We implement a simple version of file parsing and extracting of functions from python files, which can be embedded, indexed, and queried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/openai-cookbook/examples /workspaces/openai-cookbook/examples/utils\n",
      "['/workspaces/openai-cookbook/examples', '/home/codespace/.python/current/lib/python310.zip', '/home/codespace/.python/current/lib/python3.10', '/home/codespace/.python/current/lib/python3.10/lib-dynload', '', '/home/codespace/.local/lib/python3.10/site-packages', '/home/codespace/.python/current/lib/python3.10/site-packages', '/workspaces/openai-cookbook/examples/utils']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "basename = os.path.basename(os.path.abspath('.'))\n",
    "\n",
    "examplePath = os.path.abspath('./')\n",
    "utilPath = os.path.abspath('./utils/')\n",
    "print(examplePath, utilPath)\n",
    "\n",
    "if not examplePath in sys.path:\n",
    "\tsys.path.append(examplePath)\n",
    "\n",
    "if not utilPath in sys.path:\n",
    "\tsys.path.append(utilPath)\n",
    "\n",
    "print(sys.path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "We first setup some simple parsing functions that allow us to extract important information from our codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DEF_PREFIXES = ['def ', 'async def ']\n",
    "NEWLINE = '\\n'\n",
    "\n",
    "def get_function_name(code):\n",
    "    \"\"\"\n",
    "    Extract function name from a line beginning with 'def' or 'async def'.\n",
    "    \"\"\"\n",
    "    for prefix in DEF_PREFIXES:\n",
    "        if code.startswith(prefix):\n",
    "            return code[len(prefix): code.index('(')]\n",
    "\n",
    "\n",
    "def get_until_no_space(all_lines, i):\n",
    "    \"\"\"\n",
    "    Get all lines until a line outside the function definition is found.\n",
    "    \"\"\"\n",
    "    ret = [all_lines[i]]\n",
    "    for j in range(i + 1, len(all_lines)):\n",
    "        if len(all_lines[j]) == 0 or all_lines[j][0] in [' ', '\\t', ')']:\n",
    "            ret.append(all_lines[j])\n",
    "        else:\n",
    "            break\n",
    "    return NEWLINE.join(ret)\n",
    "\n",
    "\n",
    "def get_functions(filepath):\n",
    "    \"\"\"\n",
    "    Get all functions in a Python file.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        all_lines = file.read().replace('\\r', NEWLINE).split(NEWLINE)\n",
    "        for i, l in enumerate(all_lines):\n",
    "            for prefix in DEF_PREFIXES:\n",
    "                if l.startswith(prefix):\n",
    "                    code = get_until_no_space(all_lines, i)\n",
    "                    function_name = get_function_name(code)\n",
    "                    yield {\n",
    "                        'code': code,\n",
    "                        'function_name': function_name,\n",
    "                        'filepath': filepath,\n",
    "                    }\n",
    "                    break\n",
    "\n",
    "\n",
    "def extract_functions_from_repo(code_root):\n",
    "    \"\"\"\n",
    "    Extract all .py functions from the repository.\n",
    "    \"\"\"\n",
    "    code_files = list(code_root.glob('**/*.py'))\n",
    "\n",
    "    num_files = len(code_files)\n",
    "    print(f'Total number of .py files: {num_files}')\n",
    "\n",
    "    if num_files == 0:\n",
    "        print('Verify openai-python repo exists and code_root is set correctly.')\n",
    "        return None\n",
    "\n",
    "    all_funcs = [\n",
    "        func\n",
    "        for code_file in code_files\n",
    "        for func in get_functions(str(code_file))\n",
    "    ]\n",
    "\n",
    "    num_funcs = len(all_funcs)\n",
    "    print(f'Total number of functions extracted: {num_funcs}')\n",
    "\n",
    "    return all_funcs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "\n",
    "We'll first load the openai-python folder and extract the needed information using the functions we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/openai-cookbook/openai-python\n",
      "Total number of .py files: 239\n",
      "Total number of functions extracted: 180\n"
     ]
    }
   ],
   "source": [
    "code_root = Path(os.path.abspath('../openai-python'))\n",
    "\n",
    "print(code_root)\n",
    "\n",
    "# Extract all functions from the repository\n",
    "all_funcs = extract_functions_from_repo(code_root)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our content, we can pass the data to the `text-embedding-3-small` model and get back our vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>function_name</th>\n",
       "      <th>filepath</th>\n",
       "      <th>code_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def parse_obj(model: type[_ModelT], value: obj...</td>\n",
       "      <td>parse_obj</td>\n",
       "      <td>src/openai/_compat.py</td>\n",
       "      <td>[0.0069079105742275715, 0.07924877852201462, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def field_is_required(field: FieldInfo) -&gt; boo...</td>\n",
       "      <td>field_is_required</td>\n",
       "      <td>src/openai/_compat.py</td>\n",
       "      <td>[-0.003936341032385826, 0.0646929144859314, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>def field_get_default(field: FieldInfo) -&gt; Any...</td>\n",
       "      <td>field_get_default</td>\n",
       "      <td>src/openai/_compat.py</td>\n",
       "      <td>[-0.0006164583610370755, -0.001203915220685303...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>def field_outer_type(field: FieldInfo) -&gt; Any:...</td>\n",
       "      <td>field_outer_type</td>\n",
       "      <td>src/openai/_compat.py</td>\n",
       "      <td>[-0.01046344731003046, 0.03492168337106705, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>def get_model_config(model: type[pydantic.Base...</td>\n",
       "      <td>get_model_config</td>\n",
       "      <td>src/openai/_compat.py</td>\n",
       "      <td>[0.00933151226490736, 0.015094761736690998, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                code      function_name  \\\n",
       "0  def parse_obj(model: type[_ModelT], value: obj...          parse_obj   \n",
       "1  def field_is_required(field: FieldInfo) -> boo...  field_is_required   \n",
       "2  def field_get_default(field: FieldInfo) -> Any...  field_get_default   \n",
       "3  def field_outer_type(field: FieldInfo) -> Any:...   field_outer_type   \n",
       "4  def get_model_config(model: type[pydantic.Base...   get_model_config   \n",
       "\n",
       "                filepath                                     code_embedding  \n",
       "0  src/openai/_compat.py  [0.0069079105742275715, 0.07924877852201462, -...  \n",
       "1  src/openai/_compat.py  [-0.003936341032385826, 0.0646929144859314, 0....  \n",
       "2  src/openai/_compat.py  [-0.0006164583610370755, -0.001203915220685303...  \n",
       "3  src/openai/_compat.py  [-0.01046344731003046, 0.03492168337106705, 0....  \n",
       "4  src/openai/_compat.py  [0.00933151226490736, 0.015094761736690998, 0....  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.embeddings_utils import get_embedding\n",
    "df = pd.DataFrame(all_funcs)\n",
    "# todo token test\n",
    "df = df.head(5)\n",
    "df['code_embedding'] = df['code'].apply(lambda x: get_embedding(x, model='text-embedding-3-small'))\n",
    "df['filepath'] = df['filepath'].map(lambda x: Path(x).relative_to(code_root))\n",
    "df.to_csv(\"data/code_search_openai-python.csv\", index=False)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "Let's test our endpoint with some simple queries. If you're familiar with the `openai-python` repository, you'll see that we're able to easily find functions we're looking for only a simple English description.\n",
    "\n",
    "We define a search_functions method that takes our data that contains our embeddings, a query string, and some other configuration options. The process of searching our database works like such:\n",
    "\n",
    "1. We first embed our query string (code_query) with `text-embedding-3-small`. The reasoning here is that a query string like 'a function that reverses a string' and a function like 'def reverse(string): return string[::-1]' will be very similar when embedded.\n",
    "2. We then calculate the cosine similarity between our query string embedding and all data points in our database. This gives a distance between each point and our query.\n",
    "3. We finally sort all of our data points by their distance to our query string and return the number of results requested in the function parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.embeddings_utils import cosine_similarity\n",
    "\n",
    "def search_functions(df, code_query, n=3, pprint=True, n_lines=7):\n",
    "    embedding = get_embedding(code_query, model='text-embedding-3-small')\n",
    "    df['similarities'] = df.code_embedding.apply(lambda x: cosine_similarity(x, embedding))\n",
    "\n",
    "    res = df.sort_values('similarities', ascending=False).head(n)\n",
    "    if pprint:\n",
    "        for r in res.iterrows():\n",
    "            print(f\"{r[1].filepath}:{r[1].function_name}  score={round(r[1].similarities, 3)}\")\n",
    "            print(\"\\n\".join(r[1].code.split(\"\\n\")[:n_lines]))\n",
    "            print('-' * 70)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src/openai/_compat.py:field_get_default  score=0.605\n",
      "def field_get_default(field: FieldInfo) -> Any:\n",
      "    value = field.get_default()\n",
      "    if PYDANTIC_V2:\n",
      "        from pydantic_core import PydanticUndefined\n",
      "\n",
      "        if value == PydanticUndefined:\n",
      "            return None\n",
      "----------------------------------------------------------------------\n",
      "src/openai/_compat.py:field_is_required  score=0.379\n",
      "def field_is_required(field: FieldInfo) -> bool:\n",
      "    if PYDANTIC_V2:\n",
      "        return field.is_required()\n",
      "    return field.required  # type: ignore\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "src/openai/_compat.py:field_outer_type  score=0.372\n",
      "def field_outer_type(field: FieldInfo) -> Any:\n",
      "    if PYDANTIC_V2:\n",
      "        return field.annotation\n",
      "    return field.outer_type_  # type: ignore\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# res = search_functions(df, 'fine-tuning input data validation logic', n=3)\n",
    "res = search_functions(df, 'get field default', n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src/openai/_compat.py:field_outer_type  score=0.149\n",
      "def field_outer_type(field: FieldInfo) -> Any:\n",
      "    if PYDANTIC_V2:\n",
      "        return field.annotation\n",
      "    return field.outer_type_  # type: ignore\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "src/openai/_compat.py:field_get_default  score=0.097\n",
      "def field_get_default(field: FieldInfo) -> Any:\n",
      "    value = field.get_default()\n",
      "    if PYDANTIC_V2:\n",
      "        from pydantic_core import PydanticUndefined\n",
      "\n",
      "        if value == PydanticUndefined:\n",
      "            return None\n",
      "        return value\n",
      "    return value\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "res = search_functions(df, 'find common suffix', n=2, n_lines=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = search_functions(df, 'Command line interface for fine-tuning', n=1, n_lines=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
